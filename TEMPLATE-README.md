# iDART: Synthesizing Interactive Human Behavior
**Course group project for Digital Humans, ETH ZÃ¼rich, FS2025.**

## Setup

This section describes the setup and installation for the code of the group project. See the description of DART ([Getting Started](./DART-README.md#getting-started)) for the complete setup.

### Requirements and Environment

This setup uses a conda environment. We recommend to use miniconda ([Miniconda - ANACONDA](https://www.anaconda.com/docs/getting-started/miniconda/main)).

```
conda env create -f environment.yml
conda activate iDART
```

The experimental setup used 2 Intel Xeon CPUs and 1 NVIDIA GTX 1080 Ti from the student cluster.

### Download Data and Model Checkpoints

The project depends on model checkpoints and data sets from DART and data for the body models. Please follow the links, download the material, unpack and merge it with this repository. 
- [DART data - Google Drive](https://drive.google.com/drive/folders/1vJg3GFVPT6kr6cA0HrQGmiAEBE2dkaps?usp=drive_link): folders can be copied into the root directory.
- [SMPL-X body model](https://download.is.tue.mpg.de/download.php?domain=smplx&sfile=smplx_lockedhead_20230207.zip): insert into data folder (exact structure below)
- [SMPL-H body model](https://download.is.tue.mpg.de/download.php?domain=mano&resume=1&sfile=smplh.tar.xz): insert into smplx folder (exact structure below)

<details>
  <summary> Root folder structure </summary>

  ```
  .
  â”œâ”€â”€ config_files
  â”œâ”€â”€ control
  â”œâ”€â”€ data             *new
  â”œâ”€â”€ data_loaders
  â”œâ”€â”€ data_scripts
  â”œâ”€â”€ demos
  â”œâ”€â”€ diffusion
  â”œâ”€â”€ environment.yml
  â”œâ”€â”€ evaluation
  â”œâ”€â”€ misc
  â”œâ”€â”€ mld
  â”œâ”€â”€ mld_denoiser    *new
  â”œâ”€â”€ model
  â”œâ”€â”€ mvae            *new
  â”œâ”€â”€ policy_train    *new
  â”œâ”€â”€ README.md
  â”œâ”€â”€ scenes
  â”œâ”€â”€ utils
  â””â”€â”€ visualize
  ...
  ``` 
</details>

<details>
  <summary> Data folder structure </summary>

  ```
  data
  â”œâ”€â”€ action_statistics.json
  â”œâ”€â”€ fps_dict_all.json
  â”œâ”€â”€ fps_dict.json
  â”œâ”€â”€ hml3d_smplh
  â”‚Â Â  â””â”€â”€ seq_data_zero_male
  â”œâ”€â”€ inbetween
  â”‚Â Â  â””â”€â”€ pace_in_circles
  â”œâ”€â”€ joint_skin_dist.json
  â”œâ”€â”€ optim_interaction
  â”‚Â Â  â”œâ”€â”€ climb_down.json
  â”‚Â Â  â””â”€â”€ sit.json
  â”œâ”€â”€ scenes
  â”‚Â Â  â””â”€â”€ demo
  â”œâ”€â”€ seq_data_zero_male
  â”‚Â Â  â”œâ”€â”€ mean_std_h1_f1.pkl
  â”‚Â Â  â”œâ”€â”€ mean_std_h2_f16.pkl
  â”‚Â Â  â”œâ”€â”€ mean_std_h2_f8.pkl
  â”‚Â Â  â”œâ”€â”€ train_text_embedding_dict.pkl
  â”‚Â Â  â””â”€â”€ val_text_embedding_dict.pkl
  â”œâ”€â”€ smplx_lockedhead_20230207                        *from other source
  â”‚Â Â  â””â”€â”€ models_lockedhead                            *unpack and move models here
  â”œâ”€â”€ stand_20fps.pkl
  â”œâ”€â”€ stand.pkl
  â”œâ”€â”€ test_locomotion
  â”‚Â Â  â”œâ”€â”€ demo_walk.json
  â”‚Â Â  â”œâ”€â”€ random.json
  â”‚Â Â  â”œâ”€â”€ test_hop_long.json
  â”‚Â Â  â”œâ”€â”€ test_run_long.json
  â”‚Â Â  â””â”€â”€ test_walk_long.json
  â””â”€â”€ traj_test
      â”œâ”€â”€ dense_frame180_walk_circle
      â”œâ”€â”€ dense_frame180_wave_right_hand_circle
      â”œâ”€â”€ sparse_frame180_walk_square
      â””â”€â”€ sparse_punch
  ```
</details>
  
<details>
  <summary> SMPL-X folder structure </summary>

  ```
  data/smplx_lockedhead_20230207/
  â””â”€â”€ models_lockedhead
      â”œâ”€â”€ smplh                     *from MANO/SMPL-H
      â”‚Â Â  â”œâ”€â”€ female
      â”‚Â Â  â”œâ”€â”€ info.txt
      â”‚Â Â  â”œâ”€â”€ LICENSE.txt
      â”‚Â Â  â”œâ”€â”€ male
      â”‚Â Â  â””â”€â”€ neutral
      â””â”€â”€ smplx                     *from SMPL-X
          â”œâ”€â”€ md5sums.txt
          â”œâ”€â”€ SMPLX_FEMALE.npz
          â”œâ”€â”€ SMPLX_MALE.npz
          â””â”€â”€ SMPLX_NEUTRAL.npz
  ```
</details>

#### âš ï¸ IMPORTANT
Use the correct names for the folders, especially for the SMPl-X folder, and be careful with data folder, it already contains some necessary files.

#### **Data Set Description**

**ds002748 (v.1.0.1):** Two sessions of resting state with closed eyes for patients with depression in treatment course (NFB, CBT or No treatment groups)

This dataset was used for the resting state network analysis for patients with mild depression. There are two session of RS with 2-month interval, 3 groups of patients: no treatment, CBT, or fmri-NFB treatment. A session consists of 100 dynamic scans with TR = 2.5 s and 25 slices.

https://openneuro.org/datasets/ds003007/versions/1.0.1

**ds002748 (v.1.0.5):** Resting state with closed eyes for patients with depression and healthy participants

This dataset was used for the resting state network analysis. There are 51 subjects with mild depression and 21 healthy controls. A session consist of 100 dynamic scans with TR = 2.5 s and 25 slices.

https://openneuro.org/datasets/ds002748/versions/1.0.5

### âš ï¸ IMPORTANT
Only download the subjects `sub-51` up to `sub-72` to receive the healthy subjects.

### âš ï¸ IMPORTANT
Only download the subjects `sub-51` up to `sub-72` to receive the healthy subjects.

### âš ï¸ IMPORTANT
Only download the subjects `sub-51` up to `sub-72` to receive the healthy subjects.

## Guideline

Open Matlab and go to the project repository. Next, run following command. This will run the pipeline in right order.

```
for preprocessing:
run('src/fmri_prepro_depression.m')
run('src/fmri_prepro_healthy.m')

for statistical analysis:
run('src/rDCM_healthy_vs_depressed_analysis.m')
run('src/rDCM_three_group_treatment_analysis.m')
run('src/rDCM_treatment_pre_post_analysis.m')

for svm modeling:
run('src/svm_routine.m')

the rest of .m files are helper functions
```
### ğŸ“ NOTE  
- Preprocessing fMRI data can take a **very long time**. On the local machine used, it took approximately **8â€“12 hours** to preprocess everything
- appendix folder contains 2 codes that were not used for the final conclusions because they didn't show significant results (hypotheses_overall_results.m, figures in that folder obtained from here) or very slow accuracy predictions (appendix/svm_treat_pred.m). Nevertheless, they are part of the analysis development and/or future research.

## Authors 

Areli Balderas Maza: abalderas@student.ethz.ch 
David Blickenstorfer: davidbl@student.ethz.ch 
Zhining Zhang: zhinzhang@student.ethz.ch

## Acknowledgment

The authors thanks Dr. Heinzle Jakob for his supervising during the project, Computational Psychiatry Lab for providing the rDCM toolbox, and the developers of SPM12 for providing neuroimaging tools.

## License
The code was developed at University of Zurich and ETH Zurich and is part of the course: **Translational Neuromodeling, 227-0973-00L**. 